{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-x7d3b7Az_9Z",
        "03q3FNj9xbmO",
        "Uh6GU4TQxuyn",
        "_a8Rw-1dzhOq"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_Pgj5hksLOv"
      },
      "outputs": [],
      "source": [
        "# Pytorch Geometric Installation code\n",
        "!pip install -q torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
        "!pip install -q torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
        "!pip install -q git+https://github.com/rusty1s/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing and getting familiar with Data"
      ],
      "metadata": {
        "id": "-x7d3b7Az_9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Cora Dataset (Which consists of scientific publications)\n",
        "# and do the needed transformation on it\n",
        "\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "\n",
        "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())"
      ],
      "metadata": {
        "id": "4W4GR_13s13D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get some basic info about the dataset\n",
        "\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "print('\\n')\n",
        "\n",
        "# Only one graph, so use it as the data\n",
        "data = dataset[0]  \n",
        "\n",
        "# Gather some statistics about the graph.\n",
        "print(data)\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Is undirected: {data.is_undirected()}')"
      ],
      "metadata": {
        "id": "JxsGRxvOtg80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.x.shape) # equal to Nodes*features"
      ],
      "metadata": {
        "id": "8FnXgo-Rwxjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#labels\n",
        "data.y"
      ],
      "metadata": {
        "id": "0RninVBrxBZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.edge_index.t()"
      ],
      "metadata": {
        "id": "82QVuEJwxCGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  # GNN model for Node Classification"
      ],
      "metadata": {
        "id": "03q3FNj9xbmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv #GATConv\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "\n",
        "        # Initialize the layers\n",
        "        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.out = Linear(hidden_channels, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # First Message Passing Layer (Transformation)\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        # Second Message Passing Layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        # Output layer \n",
        "        x = F.softmax(self.out(x), dim=1)\n",
        "        return x\n",
        "\n",
        "model = GCN(hidden_channels=16)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "NojZbpSOxCTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Evaluation"
      ],
      "metadata": {
        "id": "Uh6GU4TQxuyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = GCN(hidden_channels=16)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "data = data.to(device)\n",
        "\n",
        "# Initialize Optimizer\n",
        "learning_rate = 0.01\n",
        "decay = 5e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), \n",
        "                             lr=learning_rate, \n",
        "                             weight_decay=decay)\n",
        "# Define loss function \n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "def train():\n",
        "      model.train()\n",
        "      optimizer.zero_grad() \n",
        "      # Use all data as input, because all nodes have node features\n",
        "      out = model(data.x, data.edge_index)  \n",
        "      # Only use nodes with labels available for loss calculation\n",
        "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  \n",
        "      loss.backward() \n",
        "      optimizer.step()\n",
        "      return loss\n",
        "\n",
        "def test():\n",
        "      model.eval()\n",
        "      out = model(data.x, data.edge_index)\n",
        "      # Use the class with highest probability.\n",
        "      pred = out.argmax(dim=1)  \n",
        "      # Check against ground-truth labels.\n",
        "      test_correct = pred[data.test_mask] == data.y[data.test_mask]  \n",
        "      # Calculate accuracy\n",
        "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  \n",
        "      return test_acc\n",
        "\n",
        "losses = []\n",
        "for epoch in range(0, 1001):\n",
        "    loss = train()\n",
        "    losses.append(loss)\n",
        "    if epoch % 100 == 0:\n",
        "      print('Epoch: {}, Loss: {}'.format(epoch, loss))"
      ],
      "metadata": {
        "id": "VJmmMXjzxyhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "_a8Rw-1dzhOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "losses_float = [float(loss.cpu().detach().numpy()) for loss in losses] \n",
        "loss_indices = [i for i,l in enumerate(losses_float)] \n",
        "plt = sns.lineplot(loss_indices, losses_float)\n",
        "plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J3927iQy77N",
        "outputId": "13809420-f557-42fb-f234-59db10131e78"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9, Loss: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gmh2L2ZHzEAS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}